#!/usr/bin/env python
from __future__ import absolute_import

import argparse
import glob
import logging
import os
import shutil
import subprocess
import sys
import tarfile
import zipfile
from collections import defaultdict
from itertools import imap, chain

try:
    from urllib.parse import quote
except ImportError:
    from urllib import quote

from pip.backwardcompat import ConfigParser
from pip.download import _download_url, _get_response_from_url
from pip.index import PackageFinder
from pip.locations import default_config_file
from pip.req import InstallRequirement


DEFAULT_REQUIREMENTS_FILE = 'requirements.in'
GLOB_PATTERN = '*requirements.in'


def flatten(list_of_lists):
    """Flatten an iterable of iterables."""
    return chain.from_iterable(list_of_lists)


class Spec(object):
    @classmethod
    def from_line(cls, line):
        """Parses a spec line from a requirements file and returns a Spec."""
        from pkg_resources import Requirement
        req = Requirement.parse(line)
        return cls(req.project_name, req.specs)

    def __init__(self, name, specs, source=None):
        """The Spec class represents a package version specification,
        typically given by a single line in a requirements.txt file.

        Each Spec belongs to a single package name, and can have multiple
        'specs' (lowercase), which are the famous (qualifier, version) tuples.

        The source is an instance of SpecSource, and defines where this spec
        comes from.
        """
        self.name = name
        self.specs = specs if specs else []
        self.source = source

    def __unicode__(self):
        specs_string = ','.join(map(''.join, self.specs))
        return '%s%s' % (self.name, specs_string)

    def __str__(self):
        return str(unicode(self))

    def __repr__(self):
        return str(self)


class SpecSource(object):
    def __str__(self):
        return str(unicode(self))


class FileSource(SpecSource):
    def __init__(self, filename, lineno):
        """Records a given filename and line number as a spec source."""
        self.filename = filename
        self.lineno = lineno

    def __unicode__(self):
        return '%s:%s' % (self.filename, self.lineno)

class InferredSource(SpecSource):
    def __init__(self):
        """Records that this spec source was inferred."""
        pass

    def __unicode__(self):
        return 'inferred'

class SpecSet(object):
    def __init__(self):
        """A collection of Spec instances that can be normalized and used for
        conflict detection.
        """
        self._byname = defaultdict(list)
        self._items = []

    def add_specs(self, iterable):
        for spec in iterable:
            self.add_spec(spec)

    def add_spec(self, spec):
        self._items.append(spec)
        self._byname[spec.name].append(spec)

    def normalize_specs_for_name(self, name):
        # TODO: This method should not lose source information, as it does
        # right now.  When normalizing, we might drop a few specs, but for the
        # ones we are keeping, the source should remain clear.

        """Normalizes specs for the given package name.

        Example before normalizing:
            [
             Spec('Django', [('>=', '1.3.1'), ('<=', '1.5.0')]),
             Spec('Django', [('>', '1.3.0'), ('<=', '1.3.2')])
            ]

        After normalizing:
            [Spec('Django', [('>=', '1.3.1'), ('<=', '1.3.2')])]

        Example before normalizing:
            [
             Spec('Django', [('>=', '1.3.2'), ('<=', '1.5.0')]),
             Spec('Django', [('>', '1.3.0'), ('<=', '1.3.2')])
            ]

        After normalizing:
            [Spec('Django', [('==', '1.3.2')])]
        """
        specs = list(flatten(map(lambda s: s.specs, self._byname[name])))

        # First, group the flattened spec list by qualifier
        by_qualifiers = defaultdict(list)
        for spec in specs:
            qualifier, version = spec
            by_qualifiers[qualifier].append(version)

        # For each qualifier type, apply selection logic.  For the unequality
        # qualifiers, select the value that yields the narrowest range
        # possible.

        # Pick the smallest less-than spec
        if '<' in by_qualifiers:
            by_qualifiers['<'] = sorted(by_qualifiers['<'])[0]
        if '<=' in by_qualifiers:
            by_qualifiers['<='] = sorted(by_qualifiers['<='])[0]

        if '<' in by_qualifiers and '<=' in by_qualifiers:
            if by_qualifiers['<'] <= by_qualifiers['<=']:
                # < xyz wins over <= xyz
                del by_qualifiers['<=']
            else:
                del by_qualifiers['<']

        # Pick the highest greater-than spec
        if '>' in by_qualifiers:
            by_qualifiers['>'] = sorted(by_qualifiers['>'])[-1]
        if '>=' in by_qualifiers:
            by_qualifiers['>='] = sorted(by_qualifiers['>='])[-1]

        if '>' in by_qualifiers and '>=' in by_qualifiers:
            if by_qualifiers['>'] >= by_qualifiers['>=']:
                # > xyz wins over >= xyz
                del by_qualifiers['>=']
            else:
                del by_qualifiers['>']

        # Normalize less-than/greater-than in the specific case where they
        # overlap on a specific version
        if '>=' in by_qualifiers and '<=' in by_qualifiers:
            if by_qualifiers['>='] == by_qualifiers['<=']:
                by_qualifiers['=='].append(by_qualifiers['<='])
                del by_qualifiers['>=']
                del by_qualifiers['<=']

        # Detect any conflicts
        if '==' in by_qualifiers:
            # Multiple '==' keys are conflicts
            assert len(set(by_qualifiers['=='])) <= 1, 'Conflict! %s' % (' with '.join(map(lambda v: '%s==%s' % (name, v), by_qualifiers['=='],)))

            # Pick the only == qualifier
            by_qualifiers['=='] = by_qualifiers['=='][0]

            # Any non-'==' key is a conflict if the pinned version does not
            # fall in that range.  Otherwise, the unequality variant can be
            # removed from the spec set.
            pinned_version = by_qualifiers['==']
            for qual, value in by_qualifiers.items():
                if qual == '==':
                    continue

                # Perform conflict checks
                if qual == '>':
                    assert pinned_version > value, 'Conflict: %s==%s with %s>%s' % (name, pinned_version, name, value)
                if qual == '>=':
                    assert pinned_version >= value, 'Conflict: %s==%s with %s>=%s' % (name, pinned_version, name, value)
                if qual == '<':
                    assert pinned_version < value, 'Conflict: %s==%s with %s<%s' % (name, pinned_version, name, value)
                if qual == '<=':
                    assert pinned_version <= value, 'Conflict: %s==%s with %s<=%s' % (name, pinned_version, name, value)

                # If no conflicts are found, prefer the pinned version and
                # discard the inequality spec
                del by_qualifiers[qual]
        else:
            # Checks for conflicts due to non-overlapping ranges
            less_than = None
            if '<' in by_qualifiers:
                less_than = by_qualifiers['<']
                less_than_op = '<'
            elif '<=' in by_qualifiers:
                less_than = by_qualifiers['<=']
                less_than_op = '<='

            greater_than = None
            if '>' in by_qualifiers:
                greater_than = by_qualifiers['>']
                greater_than_op = '>'
            elif '>=' in by_qualifiers:
                greater_than = by_qualifiers['>=']
                greater_than_op = '>='

            if less_than and greater_than:
                assert less_than > greater_than, 'Conflict: %s%s and %s%s' % (less_than_op, less_than, greater_than_op, greater_than)

        inferred_spec = Spec(name, by_qualifiers.items(), source=InferredSource())
        return inferred_spec

    def normalize(self):
        # TODO: Would it be nicer if this function returns a new SpecSet
        # instance?  I think so.

        self._normalized_by_name = {}
        for name in self._byname:
            self._normalized_by_name[name] = self.normalize_specs_for_name(name)

    def __str__(self):
        self.normalize()
        lines = []
        for spec in self._normalized_by_name.values():
            lines.append(unicode(spec))
        return '\n'.join(lines)



def setup_logging(verbose):
    if verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO

    logging.basicConfig(level=level, format='%(message)s')


def parse_args():
    parser = argparse.ArgumentParser(
            description='Compiles requirements.txt from requirements.in specs.')
    parser.add_argument('--dry-run', action='store_true', default=False,
            help="Only show what would happen, don't change anything")
    parser.add_argument('--verbose', '-v', action='store_true', default=False,
            help='Show more output')
    parser.add_argument('files', nargs='*')
    return parser.parse_args()


def get_pip_cache_root():
    """Returns pip's cache root, or None if no such cache root is configured."""
    pip_config = ConfigParser.RawConfigParser()
    pip_config.read([default_config_file])
    download_cache = None
    try:
        for key, value in pip_config.items('global'):
            if key == 'download-cache':
                download_cache = value
                break
    except ConfigParser.NoSectionError:
        pass
    if download_cache is not None:
        download_cache = os.path.expanduser(download_cache)
    return download_cache


def resolve_deps(filename):
    name, ext = os.path.splitext(filename)
    if not ext == '.in':
        raise ValueError("Top-level requirements should be named "
                         "*requirements.in")
    with open(filename, 'r') as f:
        reqs = f.read()
    download_dir = os.path.join(os.path.expanduser('~'),
                                '.pip-tools', 'cache')

    if not os.path.isdir(download_dir):
        os.makedirs(download_dir)

    deps = {}

    for line in reqs.splitlines():
        resolve_dep(line, deps)

    reqs = "\n".join(sorted(deps.keys()))
    with open('{}.txt'.format(name), 'w') as f:
        f.write(reqs + '\n')


def extract_archive(path, build_dir):
    if (path.endswith('.tar.gz') or
        path.endswith('.tar') or
        path.endswith('.tar.bz2') or
        path.endswith('.tgz')):

        archive = tarfile.open(path)
    elif path.endswith('.zip'):
        archive = zipfile.ZipFile(path)
    else:
        assert False, "Unsupported archive file: {}".format(path)

    archive.extractall(build_dir)
    archive.close()


def has_egg_info(name, dist_dir):
    try:
        subprocess.check_call([sys.executable, 'setup.py', 'egg_info'],
                              cwd=dist_dir, stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    except subprocess.CalledProcessError:
        logging.debug("egg_info failed for {}".format(name))
        return False
    return True


def read_requires(dist_dir, name):
    egg_info_dir = '{0}.egg-info'.format(name.replace('-', '_'))
    for dirpath, dirnames, filenames in os.walk(dist_dir):
        if egg_info_dir in dirnames:
            requires = os.path.join(dirpath, egg_info_dir, 'requires.txt')
            if not os.path.exists(requires):
                logging.debug("{} has no declared dependencies".format(name))
                break
            return requires


def resolve_dep(line, deps):
    logging.info("Resolving {}".format(line))
    path = download_requirement(line)

    build_dir = os.path.join(os.path.dirname(path), 'build')
    if os.path.exists(build_dir):
        shutil.rmtree(build_dir)

    extract_archive(path, build_dir)

    name = os.listdir(build_dir)[0]
    dist_dir = os.path.join(build_dir, name)
    name, version = name.rsplit('-', 1)
    deps['{0}=={1}'.format(name, version)] = path

    if not has_egg_info(name, dist_dir):
        return

    requires = read_requires(dist_dir, name)
    if not requires:
        return

    with open(requires, 'r') as requirements:
        for dep in requirements.readlines():
            dep = dep.strip()
            if dep == '[test]' or not dep:
                break
            resolve_dep(dep, deps)


def download_requirement(line):
    req = InstallRequirement.from_line(line)
    finder = PackageFinder(
        find_links=[],
        index_urls=['http://pypi.python.org/simple/'],
        use_mirrors=True,
        mirrors=[],
    )
    found = finder.find_requirement(req, False)

    download_dir = os.path.join(os.path.expanduser('~'),
                                '.pip-tools', 'cache')
    filename = quote(found.url.split('#')[0], '')
    final_path = os.path.join(download_dir, filename)
    if os.path.exists(final_path):
        # requirement already cached
        return final_path

    pip_cache_root = get_pip_cache_root()
    if pip_cache_root:
        cache_path = os.path.join(pip_cache_root, filename)
        if os.path.exists(cache_path):
            # pip has a cached version, copy it
            shutil.copyfile(cache_path, final_path)

    else:
        # actually download the requirement
        response = _get_response_from_url(found.url.split('#')[0], found)
        _download_url(response, found, final_path)
    return final_path

def walk_specfile(filename):
    """Walks over the given file, and returns (req, filename, lineno)
    tuples for each entry.
    """
    with open(filename, 'r') as f:
        reqs = f.read()

    for lineno, line in enumerate(reqs.splitlines(), 1):
        line = line.strip()
        if not line or line.startswith('#'):
            continue

        spec = Spec.from_line(line)
        spec.source = FileSource(filename, lineno)
        yield spec


def collect_source_specs(filenames):
    """This function collects all of the (primary) source specs into
    a flattened list of specs.
    """
    logging.debug('===> Collecting source requirements')
    for filename in filenames:
        for spec in walk_specfile(filename):
            logging.debug('%s: %s' % (spec.source, spec))
            yield spec


def compile_specs(source_files, dry_run=False):
    top_level_specs = collect_source_specs(source_files)

    spec_set = SpecSet()
    spec_set.add_specs(top_level_specs)

    print spec_set  # normalizes the spec set and prints the resulting set

    # TODO: Implement the rest
    # We have the normalized spec_set for the top-level dependencies.
    #
    # Still to be done:
    # - For the normalized spec set, try to find packages using the
    #   PackageFinder.  If not found, the spec can't be compiled.
    # - Get a list of next-level dependency Specs (this will mean some
    #   download, unarchive, inspect work)
    # - Add those new specs to the SpecSet, and normalize() again.
    # - Repeat until no new specs are added.


def main():
    args = parse_args()
    setup_logging(args.verbose)

    src_files = args.files or glob.glob(GLOB_PATTERN)
    compile_specs(src_files, dry_run=args.dry_run)

    if args.dry_run:
        logging.info("Dry-run, so nothing updated.")
    else:
        logging.info("Dependencies updated.")


if __name__ == '__main__':
    main()
