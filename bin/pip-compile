#!/usr/bin/env python
from __future__ import absolute_import

import argparse
import glob
import logging
import os
import shutil
import subprocess
import sys
import tarfile
import zipfile

from piptools.cache import get_package_location
from piptools.datastructures import (Spec, SpecSet, FileSource,
                                     RequiredBySource, InferredSource)
from piptools.pypi import find_best_package_url


DEFAULT_REQUIREMENTS_FILE = 'requirements.in'
GLOB_PATTERN = '*requirements.in'


def setup_logging(verbose):
    if verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO

    logging.basicConfig(level=level, format='%(message)s')


def parse_args():
    parser = argparse.ArgumentParser(
            description='Compiles requirements.txt from requirements.in specs.')
    parser.add_argument('--dry-run', action='store_true', default=False,
            help="Only show what would happen, don't change anything")
    parser.add_argument('--verbose', '-v', action='store_true', default=False,
            help='Show more output')
    parser.add_argument('files', nargs='*')
    return parser.parse_args()


def extract_archive(path, build_dir):
    if (path.endswith('.tar.gz') or
        path.endswith('.tar') or
        path.endswith('.tar.bz2') or
        path.endswith('.tgz')):

        archive = tarfile.open(path)
    elif path.endswith('.zip'):
        archive = zipfile.ZipFile(path)
    else:
        assert False, "Unsupported archive file: {}".format(path)

    archive.extractall(build_dir)
    archive.close()


def has_egg_info(name, dist_dir):
    try:
        subprocess.check_call([sys.executable, 'setup.py', 'egg_info'],
                              cwd=dist_dir, stdout=subprocess.PIPE,
                              stderr=subprocess.PIPE)
    except subprocess.CalledProcessError:
        logging.debug("egg_info failed for {}".format(name))
        return False
    return True


def read_requires(dist_dir, name):
    egg_info_dir = '{0}.egg-info'.format(name.replace('-', '_'))
    for dirpath, dirnames, filenames in os.walk(dist_dir):
        if egg_info_dir in dirnames:
            requires = os.path.join(dirpath, egg_info_dir, 'requires.txt')
            if not os.path.exists(requires):
                logging.debug("{} has no declared dependencies".format(name))
                break
            return requires


def resolve_dep(spec, specs, required_by=None):
    """Recursively resolves the dependencies for `spec` and appends
    them to `specs`."""
    if required_by is None:
        logging.info("Resolving {}".format(spec))
    else:
        logging.info("Resolving {} (from {})".format(spec, required_by))
    link = find_best_package_url(spec)
    path = get_package_location(link)

    build_dir = os.path.join(os.path.dirname(path), 'build')
    if os.path.exists(build_dir):
        shutil.rmtree(build_dir)

    extract_archive(path, build_dir)

    name = os.listdir(build_dir)[0]
    dist_dir = os.path.join(build_dir, name)
    name, version = name.rsplit('-', 1)

    spec = Spec.from_line('{0}=={1}'.format(name, version))
    if required_by is None:
        # TODO: other source type for PyPI 'best matches'?
        spec.source = InferredSource()
    else:
        spec.source = RequiredBySource(required_by)
    specs.append(Spec.from_line('{0}=={1}'.format(name, version)))

    if not has_egg_info(name, dist_dir):
        return

    requires = read_requires(dist_dir, name)
    if not requires:
        return

    with open(requires, 'r') as requirements:
        for dep in requirements.readlines():
            dep = dep.strip()
            if dep == '[test]' or not dep:
                break
            resolve_dep(Spec.from_line(dep), specs, required_by=name)


def walk_specfile(filename):
    """Walks over the given file, and returns (req, filename, lineno)
    tuples for each entry.
    """
    with open(filename, 'r') as f:
        reqs = f.read()

    for lineno, line in enumerate(reqs.splitlines(), 1):
        line = line.strip()
        if not line or line.startswith('#'):
            continue

        spec = Spec.from_line(line)
        spec.source = FileSource(filename, lineno)
        yield spec


def collect_source_specs(filenames):
    """This function collects all of the (primary) source specs into
    a flattened list of specs.
    """
    logging.debug('===> Collecting source requirements')
    for filename in filenames:
        for spec in walk_specfile(filename):
            logging.debug('%s' % (spec.description(),))
            yield spec


def compile_specs(source_files, dry_run=False):
    top_level_specs = list(collect_source_specs(source_files))

    spec_set = SpecSet()
    spec_set.add_specs(top_level_specs)
    spec_set = spec_set.normalize()

    logging.debug('')
    logging.debug('===> Normalizing source requirements')
    #print spec_set

    from piptools.datastructures import flatten
    new_spec = SpecSet()
    for spec in flatten(spec_set._byname.values()):  # TODO: Instead of this ugliness, add an iterator interface to SpecSet
        logging.debug('Finding package match for %s' % (spec,))
        deps = []
        resolve_dep(spec, deps)
        new_spec.add_specs(deps)
    new_spec.normalize()  # checks for conflicts with all requirements pinned
    print new_spec

    # TODO: new_spec has everything pinned but for all spec files. If there
    # is only one that's not an issue but for multiple specs we need to dump
    # the appropriate dependency tree in each compiled file.


def main():
    args = parse_args()
    setup_logging(args.verbose)

    src_files = args.files or glob.glob(GLOB_PATTERN)
    compile_specs(src_files, dry_run=args.dry_run)

    if args.dry_run:
        logging.info("Dry-run, so nothing updated.")
    else:
        logging.info("Dependencies updated.")


if __name__ == '__main__':
    main()
